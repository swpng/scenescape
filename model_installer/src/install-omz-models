#!/usr/bin/env python3

# SPDX-FileCopyrightText: (C) 2022 - 2025 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

import os
import json
import shutil
import subprocess
from argparse import ArgumentParser

from generate_model_config import generate_model_config

TIMEOUT = 600
NUM_RETRIES = "6"
OMZ_DIR = "/usr/local/lib/open_model_zoo"
MODEL_DIR = os.environ.get("MODEL_DIR") if "MODEL_DIR" in os.environ else "/workspace/models"
OVMS_MODEL_DIR = os.path.join(MODEL_DIR, "ovms")
MODEL_CACHE_DIR = os.path.join(OVMS_MODEL_DIR, "cache")
OVMS_CONFIGFILE = f"{MODEL_DIR}/ovms-config.json"
OMZ_BASE_URL = "https://storage.openvinotoolkit.org/repositories/open_model_zoo/2023.0/models_bin/1"
# Special case: some public models have a different base URL
MODEL_BASE_URLS = {
  "text-recognition-resnet-fc": "https://storage.openvinotoolkit.org/repositories/open_model_zoo/public/text-recognition-resnet-fc"
}
MODEL_PROC_FOLDER_URL = "https://raw.githubusercontent.com/open-edge-platform/edge-ai-libraries/refs/heads/main/libraries/dl-streamer/samples/gstreamer/model_proc/intel/"

_DEFAULT_MODELS = [
  'person-detection-retail-0013',
  'person-reidentification-retail-0277',
  'human-pose-estimation-0001',
]

_OCR_MODELS = [
  'horizontal-text-detection-0001',
  'text-recognition-resnet-fc',
  'text-recognition-0012'
]

_ALL_MODELS = _DEFAULT_MODELS + _OCR_MODELS + [
  'pedestrian-and-vehicle-detector-adas-0001',
  'person-vehicle-bike-detection-2000',
  'person-vehicle-bike-detection-2001',
  'person-vehicle-bike-detection-2002',
  'person-vehicle-bike-detection-crossroad-0078',
  'person-vehicle-bike-detection-crossroad-1016',
  'person-attributes-recognition-crossroad-0238',
  'age-gender-recognition-retail-0013',
  'vehicle-detection-0200',
  'vehicle-detection-0201',
  'vehicle-detection-0202',
  'vehicle-detection-adas-0002',
  'vehicle-license-plate-detection-barrier-0106',
  'vehicle-attributes-recognition-barrier-0042'
]

# TODO: use download_public_models.sh for downloading supported models
# see: https://github.com/open-edge-platform/edge-ai-libraries/tree/main/libraries/dl-streamer/samples
_PUBLIC_MODELS = [
  # This is 1-channel model that is not supported by DLStreamer
  # TODO: use ch_PP-OCRv4_rec_infer
  'text-recognition-resnet-fc',
]

def _build_argparser():
  parser = ArgumentParser()
  parser.add_argument("--default", action="store_true", help="Download default models")
  parser.add_argument("--ocr", action="store_true", help="Download OCR models")
  parser.add_argument("--all", action="store_true", help="Download all models")
  parser.add_argument("--precisions", help="Donwload models with specific precisions."
                      "Comma separated value, with no extra spaces.",
                      type=str, default="FP32")
  parser.add_argument("--model_proc", action="store_true", help="Try to download model proc files for each model")
  return parser

def _make_dir(path):
  if not os.path.exists(path):
    os.makedirs(path)

  return

def _create_ovms_configfile(filepath):
  data = {
    "model_config_list" : []
  }

  _write_json(filepath, data)
  return

def _write_json(filepath, data):
  with open(filepath, "w") as datafile:
    datafile.write(json.dumps(data, indent=2))

  return

def _read_json(filepath):
  with open(filepath, 'r') as datafile:
    data = datafile.read()

  config = json.loads(data)
  return config

def _download_model(model, precisions, model_subdir, download_proc):
  # Download model files (.xml and .bin, optionally model_proc) for each specified precision from archive
  exit_code = 0
  for prec in precisions.split(","):
    prec = prec.strip()
    model_url_dir = MODEL_BASE_URLS.get(model, f"{OMZ_BASE_URL}/{model}/{prec}")
    dest_dir = os.path.join(MODEL_DIR, model_subdir, model, prec)
    _make_dir(dest_dir)
    try:
      print(f"Downloading {model} ({prec})...")
      xml_url = f"{model_url_dir}/{model}.xml"
      bin_url = f"{model_url_dir}/{model}.bin"
      subprocess.run(
        ["wget", "-nv", "-O", os.path.join(dest_dir, f"{model}.xml"), xml_url],
        timeout=TIMEOUT, check=True
      )
      subprocess.run(
        ["wget", "-nv", "-O", os.path.join(dest_dir, f"{model}.bin"), bin_url],
        timeout=TIMEOUT, check=True
      )
      if download_proc:
        proc_url = f"{MODEL_PROC_FOLDER_URL}{model}.json"
        proc_dest = os.path.join(dest_dir, f"{model}.json")
        try:
          subprocess.run(
            ["wget", "-nv", "-O", proc_dest, proc_url],
            timeout=TIMEOUT, check=True,
            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
            )
        except Exception as e:
          print(f"Info: model_proc not found for {model}")
          if os.path.exists(proc_dest):
            os.remove(proc_dest)
    except Exception as e:
      print(f"Failed to download {model} ({prec}): {e}")
      shutil.rmtree(dest_dir, ignore_errors=True)
      exit_code = 1
  return exit_code

def _copy_files(source, destination):
  dir = os.path.dirname(destination)
  _make_dir(dir)

  # Copy all files from source directory to destination
  if os.path.exists(source):
    shutil.copytree(source, destination, dirs_exist_ok=True)
  else:
    print(f"Warning: Source directory {source} does not exist")

  return

def main():
  args = _build_argparser().parse_args()
  if args.all:
    models = _ALL_MODELS
  elif args.ocr:
    models = _OCR_MODELS
  else:
    models = _DEFAULT_MODELS

  precisions = args.precisions
  proc_files = args.model_proc

  _make_dir(OVMS_MODEL_DIR)
  _make_dir(MODEL_CACHE_DIR)

  if not os.path.exists(OVMS_CONFIGFILE):
    _create_ovms_configfile(OVMS_CONFIGFILE)

  ovms_config = _read_json(OVMS_CONFIGFILE)

  ovms_config_len = len(ovms_config["model_config_list"])

  for model in models:
    model_subdir = "public" if model in _PUBLIC_MODELS else "intel"
    if not os.path.isdir(os.path.join(MODEL_DIR, model_subdir, model)):
      # Download model
      _download_model(model, precisions, model_subdir, proc_files)

      source = os.path.join(MODEL_DIR, model_subdir, model, "FP32")

      # Copy files instead of creating symlink
      destination = os.path.join(OVMS_MODEL_DIR, model, "1")
      _copy_files(source, destination)

  if len(ovms_config["model_config_list"]) > ovms_config_len:
    _write_json(OVMS_CONFIGFILE, ovms_config)

  precision = precisions.split(",")[0].strip()
  generate_model_config(MODEL_DIR, output_file="model_config.json", prefer_precision=precision)

  return

if __name__ == "__main__":
  main()
